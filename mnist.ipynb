{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  label\n",
       "0      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       "1      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      0\n",
       "2      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      4\n",
       "3      {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      1\n",
       "4      {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      9\n",
       "...                                                  ...    ...\n",
       "59995  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8\n",
       "59996  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      3\n",
       "59997  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      5\n",
       "59998  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      6\n",
       "59999  {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...      8\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"train-00000-of-00001.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x01\\x00IDATx\\x9cc`\\x18\\xcc\\x80YHH\\xa8\\xaec\\xbd\\xd4\\xb2\\xff\\xdf\\xeb\\x19\\x18\\x18\\x18X`\\x12rlV6\\x02\\xc1\\x0c\\x0c\\x0c\\x0cO&\\x05~\\xbex\\x90\\x81\\x81\\x81\\x81\\x11*g\\xb8\\x97\\x1f\\xca\\xfa\\x97\\xf4\\x95\\xe1\\xd9\\xfb\\x9b\\xc8&\\n\\xdd\\xfe\\xfb\\xf7\\xef\\xdf\\xbf\\xc7\\xb6}\\xff\\x88\\xc5\\xbe\\x809\\xd9\\x7f\\xff\\x9e\\xe5f\\xd0\\x9e\\x85\\xcd5|\\x8c\\xb3\\xfeF\\xa1\\n1\\xc1Y\\x9f\\xfe\\x7fdHab\\xc0\\x05\\xb8\\xf7\\xfdu\\xc3)\\xc9\\xa0\\xfc\\xf1\\xe1\\x82\\x1cF\\\\\\xb2\\x81\\x1f\\xfe\\xfe-\\x97\\xc4%\\xab\\xbb\\xeb\\xef\\xdfi\\xd2\\xb8d\\x05b\\xff\\xfc\\xdd\\x8d\\xdb\\xe2\\x9f\\x7f\\x7f:@\\x99,\\xa82z!\\xa6,\\x0c\\xd7\\x0ea\\xd3\\xa4>\\xe5\\xe9\\xdf\\xbf\\x7f\\x7fm\\xc3\"%Qt\\xf7\\xef\\xdf\\xbf\\x7fO\\xfaaJ\\x89;]\\xfd\\xfb\\xf7\\xef\\xdfc\\x81\\x98\\x81$\\xb4\\xfa\\xf6\\xdf\\xbf\\x7f\\xff\\x1e\\x0e\\xe0\\xc4\\x902_\\xf3\\xe8\\xef\\xdf\\xbf\\x7f\\xbf\\xb4r\\xa3\\x8a\\xb30000\\x04\\x0620\\\\\\xdf\\xfc\\xb7\\xe7\\x036WR\\x1f\\x00\\x00E\\x17^\\x80kL\\x00;\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82', 'path': None},\n",
       "       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x00\\xffIDATx\\x9cc`\\x18x`<\\xff\\xef|#\\x1cr\\x06\\xef\\xfe\\xfc\\xf9\\xf3\\x16\\xbb\\x9c\\xd9\\xe3\\xbf\\x7f\\xde\\xbf\\xfcc\\xc9\\x86)\\xc5e\\xf3\\xe0\\xcf\\xdf?\\xa7B\\xfe\\xfc\\xad\\x82\\x080!I\\xce< \\xc3\\xc0\\xc0`\\xc4s\\x90A\\x17C\\xd2\\xd8\\x9b\\x91\\xf1P)\\xe3\\x8b\\xf3\\x93\\x98\\x18\\xb1\\xb9e3\\x8fw\\xa5(\\x03\\xc3\\xdf\\xcfh\\x0eV[\\xfa\\xf7\\xe5\\x85\\x10\\x08\\xfb\\xef\\x9f\\xa5(r\\xec\\x9b\\xfe|p\\x17\\x96\\x81I\\x1eF\\x91\\xb4\\xfc\\xf3\\xc7\\x1e\\xceA\\x97<\\xf6w\\x1f\\x82\\xf3\\xff\\xef\\x11d\\xd7\\xfa\\x18\\xfc\\xdf\\x84\\x90\\xfc\\xf7\\xff\\x02\\xb2\\xc6\\xd0?\\xcf$\\xe1\\xd6\\xb7\\xff\\xdd\\xc5\\x83*y\\x1f.\\xd7\\xfc\\xe7\\xa1;\\x03\\xaa\\xe4D(\\xcb`\\xe9\\x9f\\xb5\\x0c\\xa8 \\xec\\xefC\\x08\\xa3\\xe8\\xdd\\xdfEhr\\x0c\\xa1\\x7f~N2\\x90\\r\\xdd\\xf4\\xf0\\xef\\xfd\\xe5\\x16\\x98\\x92\\x7f\\xfe<\\xbd\\xfe\\xe7\\xcf\\x9f#M\\xe8R\\x0c\\x0c2\\xc7\\xff\\xfc\\xf9\\xfb\\xe7\\xcf\\xcb\\x89\\x98R\\x0c\\x0c\\x0c\\x92\\r\\x7f\\xfe\\xfe\\xe9U\\xc5*GW\\x00\\x00\\xacpnD\\xd5#7v\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82', 'path': None},\n",
       "       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x00\\xd4IDATx\\x9cc`\\x18\\n\\xc0\\xf9\\x85:\\x03\\x03\\x03\\x03\\x03\\x13\\x03\\x03\\x03\\x83] \\xaa\\xa4\\xe9\\x19\\x06\\x84\\xa4C\\x10\\x8a\\x1c\\x93\\xa2\\x1c#\\x82wg1\\x8a\\xa4\\xf4\\xbfEH:\\x99PM\\x9d\\xc3p\\x1b!\\xa9\\'\\x8e*\\xc9\\xcf\\xb0\\x1b!\\xe9\\xc5\\x89\"\\'\\xae\\xc8\\xf0\\x14!\\xa9\\xcep\\x15Y\\xb2G\\xfc\\xd6g\\x08\\x8b\\x85\\x81\\x81\\x81\\x81\\xe14\\\\\\x86\\xcf#\\xc6\\x8d\\xa1\\xf9\\x03\\xb2\\xa4\\x10\\x03\\x03\\x83>\\x93\\xb3\\x0c[4\\xd3\\xf7\\x93?Y\\xceBU2200LK\\xff\\xf0\\x88\\x81A\\x8f\\xf1\\xcf\\xb7k\\'\\xcf\\x1c|\\xf9D\\x90\\x8d\\x01\\xa13\\xeb\\xa1\\x15\\x03\\x03\\xc3\\xa3\\x8d\\xd7N0000\\xa4\\x89\\xdec\\xc0\\tV\\xfe\\xeb\\x841\\x99\\xb0Ho\\xc0\\'\\xc9\\x80G\\x92Q\\x15\\x8f\\xe4\\x7f&<\\x92\\x0c\\x96\\xf8\\x8c\\xc5c\\xe7\\xf6\\xff8\\x1dH%\\x00\\x00\\x83y,Gt\\x0f\\x81 \\x00\\x00\\x00\\x00IEND\\xaeB`\\x82', 'path': None},\n",
       "       ...,\n",
       "       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x00\\xddIDATx\\x9cc`\\x18\\x02 \\xa1\\xf2\\xea\\xff\\xff\\x95\\x0c\\x0c\\x0c,h\\x12&\\x16\\x86!\\\\L\\x0c\\x9f\\x17\\x9ca```D\\x96\\xe1\\nq\\xf3\\xe5axt\\xe0\\xc9\\xf4\\xbf/\\xd14\\xd9\\xa4\\xdd\\xfa\\xfb\\xf7F\\xa9\\xba4\\x16\\x9b\\xcc\\xce\\xfe\\xfd\\xfbw\\xb2\\x0cVW\\xd8|\\xf8\\xfb\\xf7\\xefgy\\xecN\\x94\\n\\xb8\\xf0\\xf7\\xefdT1&\\x18\\xe3\\xd9\\x15>\\x06\\x86g\\xa8\\x92H\\xae\\xdd\\xe8\\xc8\\xfd{6\\xe3\\xf1\\xe5\\xff\\xb0\\x9a,\\\\q\\xf4\\xef\\xbf\\xbf\\x89\\xd8\\xade``\\xf08\\xf0\\xef\\x9f\\x06NY\\xb6O\\x7f\\xd5qJ2T\\xfe\\x9d\\x8f\\xe9Z\\x18\\xf8\\xcc\\xc0\\x87[\\x12\\x19`\\x91\\x9c\\x8b\\xc6\\x17\\x83\\xb3DNb8\\xe8\\xc8BMV\\x06\\x06\\x06f\\xe9\\xa4s\\x7f\\x0f\\xf1\\xc3\\x85!\\x91\\xbd\\xbe6z\\xf9\\x07\\x06\\x06\\xeex\\x06\\xa6\\x9d\\xdd\\x1f1-\\xfa\\x0b\\x01\\x95l\\xf8\\\\H\\x1d\\x00\\x00\\xbfzJ\\x1c:\\x0c\\xa5r\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82', 'path': None},\n",
       "       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x00\\xf5IDATx\\x9cc`\\xa0\"0?\\xf0L\\x1a\\xc2b\\xc2\\x90\\xe3H\\xb4\\xb9\\x8dK\\x1fG\\xe3\\x9f}\\x9c\\xb8$g\\xff\\xb9\\xc4\\x87K\\xce\\xee\\xc6q\\'\\x1cR\\xdc\\xda\\xff\\xee\\xd9\\xe1\\xd2\\xd7\\xff\\xe7\\x9e\\x00.\\xb9\\x95\\xdf.\\x08\\xe22\\xb3\\xff\\xdb\\x9bT\\\\\\xfa\\\\\\x1f\\x1d\\xcf\\xc7%\\xc7\\xf0\\xef\\xaf(\\x9a\\x08\\x0b\\x9cU\\xf3\\xbf\\xf0\\x03\\x03\\x03\\x03\\x03\\x83X\\x96\\xfd\\xff\\xd3\\x93\\x9f \\xab*\\xf8\\xb8J\\x81\\x81\\x81A\\xbe~\\xcb\\xdb?\\x7f\\xff|\\xd2B\\x96c\\xdb\\xf7\\x88\\x81\\x81\\x81A\\xfa\\xd6\\x9fC\\x8bBB\\x9a_(#K\\xe6\\xfd\\x99\\xcc\\xc0\\xc0\\xc0p\\xe8\\xefM\\x0b\\x06\\x06\\xa1\\x1b\\xbbQ\\xec~yC\\x88\\x81\\x81A\\xfa\\xd0\\xb4,N\\x86\\x9a\\xff\\xbbP\\x82\\xde\\xe1{\\x1e\\x8c\\x19>i\\xb1\\xbd\\x00\\x8ak\\xcf}\\x15b``\\xe0\\xe6\\xd6\\xb1\\xf3\\x93<\\x1d\\xf5\\x05\\xd5G2\\xef\\x8f\\xac\\x0cZy\\xf9\\xcf\\x9f\\x86\\x10v\\x8c\\x00P\\xf9\\xf8\\xe7\\xcf\\xdf\\x9b]ZZ\\x182C\\x07\\x00\\x00\\x9d\\xddQ\\x1c\\x02\\xa5\\xdd\\x7f\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82', 'path': None},\n",
       "       {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\x00\\x00\\x00\\xebIDATx\\x9cc`\\x18J\\x80\\x11]@\\x8d\\x8b\\xe1\\xd9+\\xacJ\\xed\\x12\\x8f}\\xfe\\xf7\\xef\\x8a469\\xe75\\xff\\xfe=\\xbcu\\xeb\\xed\\x0f\\r\\x06\\xd1%\\xbbQ\\xe5\"o\\xffKt\\xe6c`\\x88y^%~\\xfa\\x8d5\\x8a\\x9c\\xe4\\xcdO1,\\x0c\\x0c\\x0c\\x0c,\\x93\\xff~x\\x11\\x83\\xaa1\\xf5?T \\xf3\\xdf\\xbf\\x8d\\xdch6.\\xff\\xa2\\xc9\\xc0\\xc0\\xc0\\xees\\xfc\\xdd\\xfb8.t\\xe7\\x1c\\xa8d``\\xb2\\xdf\\xf2\\xefe\\x1d\\x16\\xb7\\xee;\\xc2\\xc7\\x94\\xf8\\xef\\xcf$\\x13l\\x1eiz\\xe8\\xbe\\xe5\\xc5V\\x1blR\\x0c\\x0cM\\xff\\xfe=\\xd3\\xc3.\\xc5\\xe6\\xfb\\xe5\\xdf\"\\x16T1&\\x18#c\\xe33\\x86K\\x7f\\xb0kl\\xfe7K\\xe6j\\x18v9\\xa7\\x8b3\\x85\\x85_\\xa2;\\x06j\\xac\\x8f.\\xcf\\xdb\\xdf\\xef\\xb3\\xb1K\\x9ea\\xe0b`\\xe1\\xdd\\x8a\\xddX\\xa9\\xa7?7\\xdc\\xfb\\xa2\\x83]\\x92\\xc1\\xf3\\xe0\\xd16\\x1cRT\\x07\\x00\\xa6BQ\\x84Q.\\'\\x99\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82', 'path': None}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mnist = df.iloc[:,0].values\n",
    "y_mnist = df.iloc[:,1].values\n",
    "x_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "1        {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "2        {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "3        {'bytes': b\"\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "4        {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "                               ...                        \n",
       "59995    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "59996    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "59997    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "59998    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "59999    {'bytes': b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHD...\n",
       "Name: image, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_mnist = []\n",
    "for x in x_mnist:\n",
    "    image = Image.open(io.BytesIO(x[\"bytes\"]))\n",
    "    pixel_list = list(image.getdata())\n",
    "    lista_mnist.append(pixel_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = np.array(lista_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_mnist = scaler.fit_transform(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.26352237\n",
      "Iteration 2, loss = 0.09626338\n",
      "Iteration 3, loss = 0.06236314\n",
      "Iteration 4, loss = 0.04811545\n",
      "Iteration 5, loss = 0.04085041\n",
      "Iteration 6, loss = 0.03225189\n",
      "Iteration 7, loss = 0.02755252\n",
      "Iteration 8, loss = 0.02455110\n",
      "Iteration 9, loss = 0.02548326\n",
      "Iteration 10, loss = 0.02169237\n",
      "Iteration 11, loss = 0.01796273\n",
      "Iteration 12, loss = 0.02080284\n",
      "Iteration 13, loss = 0.01736080\n",
      "Iteration 14, loss = 0.01578919\n",
      "Iteration 15, loss = 0.01500226\n",
      "Iteration 16, loss = 0.01797366\n",
      "Iteration 17, loss = 0.01691690\n",
      "Iteration 18, loss = 0.01682792\n",
      "Iteration 19, loss = 0.01696305\n",
      "Iteration 20, loss = 0.01701718\n",
      "Iteration 21, loss = 0.01143941\n",
      "Iteration 22, loss = 0.00907350\n",
      "Iteration 23, loss = 0.01494863\n",
      "Iteration 24, loss = 0.01487804\n",
      "Iteration 25, loss = 0.01346476\n",
      "Iteration 26, loss = 0.01055585\n",
      "Iteration 27, loss = 0.01447882\n",
      "Iteration 28, loss = 0.00749954\n",
      "Iteration 29, loss = 0.01274665\n",
      "Iteration 30, loss = 0.00987725\n",
      "Iteration 31, loss = 0.00744828\n",
      "Iteration 32, loss = 0.01079316\n",
      "Iteration 33, loss = 0.01448972\n",
      "Iteration 34, loss = 0.01026030\n",
      "Iteration 35, loss = 0.00558127\n",
      "Iteration 36, loss = 0.01277327\n",
      "Iteration 37, loss = 0.01218133\n",
      "Iteration 38, loss = 0.01208476\n",
      "Iteration 39, loss = 0.00758743\n",
      "Iteration 40, loss = 0.01231468\n",
      "Iteration 41, loss = 0.01064456\n",
      "Iteration 42, loss = 0.01147338\n",
      "Iteration 43, loss = 0.01071837\n",
      "Iteration 44, loss = 0.00909860\n",
      "Iteration 45, loss = 0.00903492\n",
      "Iteration 46, loss = 0.01139028\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.25931137\n",
      "Iteration 2, loss = 0.09427896\n",
      "Iteration 3, loss = 0.06499909\n",
      "Iteration 4, loss = 0.04963606\n",
      "Iteration 5, loss = 0.03632721\n",
      "Iteration 6, loss = 0.03414954\n",
      "Iteration 7, loss = 0.02678187\n",
      "Iteration 8, loss = 0.02691106\n",
      "Iteration 9, loss = 0.02412317\n",
      "Iteration 10, loss = 0.02046042\n",
      "Iteration 11, loss = 0.02283950\n",
      "Iteration 12, loss = 0.02528270\n",
      "Iteration 13, loss = 0.02037363\n",
      "Iteration 14, loss = 0.01268695\n",
      "Iteration 15, loss = 0.01920365\n",
      "Iteration 16, loss = 0.01398702\n",
      "Iteration 17, loss = 0.01396347\n",
      "Iteration 18, loss = 0.01402070\n",
      "Iteration 19, loss = 0.01654582\n",
      "Iteration 20, loss = 0.01504981\n",
      "Iteration 21, loss = 0.00722157\n",
      "Iteration 22, loss = 0.01091829\n",
      "Iteration 23, loss = 0.01337995\n",
      "Iteration 24, loss = 0.01401634\n",
      "Iteration 25, loss = 0.01156070\n",
      "Iteration 26, loss = 0.01440143\n",
      "Iteration 27, loss = 0.01273388\n",
      "Iteration 28, loss = 0.01195155\n",
      "Iteration 29, loss = 0.01036210\n",
      "Iteration 30, loss = 0.00608036\n",
      "Iteration 31, loss = 0.01073369\n",
      "Iteration 32, loss = 0.01224507\n",
      "Iteration 33, loss = 0.01406528\n",
      "Iteration 34, loss = 0.00840512\n",
      "Iteration 35, loss = 0.01002500\n",
      "Iteration 36, loss = 0.01001172\n",
      "Iteration 37, loss = 0.01123126\n",
      "Iteration 38, loss = 0.01195966\n",
      "Iteration 39, loss = 0.01526268\n",
      "Iteration 40, loss = 0.00642086\n",
      "Iteration 41, loss = 0.01194869\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.25854264\n",
      "Iteration 2, loss = 0.09976113\n",
      "Iteration 3, loss = 0.06691813\n",
      "Iteration 4, loss = 0.04435129\n",
      "Iteration 5, loss = 0.04101808\n",
      "Iteration 6, loss = 0.03058257\n",
      "Iteration 7, loss = 0.02952892\n",
      "Iteration 8, loss = 0.02689992\n",
      "Iteration 9, loss = 0.02535241\n",
      "Iteration 10, loss = 0.02207833\n",
      "Iteration 11, loss = 0.01902035\n",
      "Iteration 12, loss = 0.01448598\n",
      "Iteration 13, loss = 0.02124428\n",
      "Iteration 14, loss = 0.01883944\n",
      "Iteration 15, loss = 0.01657289\n",
      "Iteration 16, loss = 0.01117165\n",
      "Iteration 17, loss = 0.01754134\n",
      "Iteration 18, loss = 0.01855930\n",
      "Iteration 19, loss = 0.01368235\n",
      "Iteration 20, loss = 0.01241038\n",
      "Iteration 21, loss = 0.00934858\n",
      "Iteration 22, loss = 0.01197132\n",
      "Iteration 23, loss = 0.01271765\n",
      "Iteration 24, loss = 0.01294884\n",
      "Iteration 25, loss = 0.01582293\n",
      "Iteration 26, loss = 0.00768572\n",
      "Iteration 27, loss = 0.01033635\n",
      "Iteration 28, loss = 0.00976356\n",
      "Iteration 29, loss = 0.01556092\n",
      "Iteration 30, loss = 0.01220443\n",
      "Iteration 31, loss = 0.00701147\n",
      "Iteration 32, loss = 0.01507034\n",
      "Iteration 33, loss = 0.01272828\n",
      "Iteration 34, loss = 0.00879354\n",
      "Iteration 35, loss = 0.00712244\n",
      "Iteration 36, loss = 0.00721955\n",
      "Iteration 37, loss = 0.01116322\n",
      "Iteration 38, loss = 0.00995516\n",
      "Iteration 39, loss = 0.00789993\n",
      "Iteration 40, loss = 0.01509490\n",
      "Iteration 41, loss = 0.01016944\n",
      "Iteration 42, loss = 0.00561694\n",
      "Iteration 43, loss = 0.00595303\n",
      "Iteration 44, loss = 0.00973732\n",
      "Iteration 45, loss = 0.01447637\n",
      "Iteration 46, loss = 0.01266515\n",
      "Iteration 47, loss = 0.00985366\n",
      "Iteration 48, loss = 0.00960244\n",
      "Iteration 49, loss = 0.00345289\n",
      "Iteration 50, loss = 0.00772595\n",
      "Iteration 51, loss = 0.00925517\n",
      "Iteration 52, loss = 0.01014867\n",
      "Iteration 53, loss = 0.00755722\n",
      "Iteration 54, loss = 0.01214194\n",
      "Iteration 55, loss = 0.00990924\n",
      "Iteration 56, loss = 0.00659499\n",
      "Iteration 57, loss = 0.00818953\n",
      "Iteration 58, loss = 0.01356915\n",
      "Iteration 59, loss = 0.00483081\n",
      "Iteration 60, loss = 0.00585686\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.25931064\n",
      "Iteration 2, loss = 0.09521985\n",
      "Iteration 3, loss = 0.06236801\n",
      "Iteration 4, loss = 0.04728803\n",
      "Iteration 5, loss = 0.03725507\n",
      "Iteration 6, loss = 0.03596896\n",
      "Iteration 7, loss = 0.03092338\n",
      "Iteration 8, loss = 0.02339358\n",
      "Iteration 9, loss = 0.02340641\n",
      "Iteration 10, loss = 0.02255496\n",
      "Iteration 11, loss = 0.01877817\n",
      "Iteration 12, loss = 0.02021013\n",
      "Iteration 13, loss = 0.01724941\n",
      "Iteration 14, loss = 0.01945935\n",
      "Iteration 15, loss = 0.01294204\n",
      "Iteration 16, loss = 0.01728363\n",
      "Iteration 17, loss = 0.01520854\n",
      "Iteration 18, loss = 0.01229379\n",
      "Iteration 19, loss = 0.01259777\n",
      "Iteration 20, loss = 0.01227939\n",
      "Iteration 21, loss = 0.01253603\n",
      "Iteration 22, loss = 0.00834079\n",
      "Iteration 23, loss = 0.01504682\n",
      "Iteration 24, loss = 0.00926555\n",
      "Iteration 25, loss = 0.01296230\n",
      "Iteration 26, loss = 0.01350738\n",
      "Iteration 27, loss = 0.00886807\n",
      "Iteration 28, loss = 0.01242632\n",
      "Iteration 29, loss = 0.01102233\n",
      "Iteration 30, loss = 0.01110412\n",
      "Iteration 31, loss = 0.00958101\n",
      "Iteration 32, loss = 0.01220741\n",
      "Iteration 33, loss = 0.01127981\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.26329852\n",
      "Iteration 2, loss = 0.09757559\n",
      "Iteration 3, loss = 0.06567119\n",
      "Iteration 4, loss = 0.04670125\n",
      "Iteration 5, loss = 0.03855450\n",
      "Iteration 6, loss = 0.03127454\n",
      "Iteration 7, loss = 0.02534584\n",
      "Iteration 8, loss = 0.03128522\n",
      "Iteration 9, loss = 0.02350286\n",
      "Iteration 10, loss = 0.02773719\n",
      "Iteration 11, loss = 0.02007351\n",
      "Iteration 12, loss = 0.01501122\n",
      "Iteration 13, loss = 0.02031525\n",
      "Iteration 14, loss = 0.01491455\n",
      "Iteration 15, loss = 0.01395763\n",
      "Iteration 16, loss = 0.01782224\n",
      "Iteration 17, loss = 0.01574269\n",
      "Iteration 18, loss = 0.01660065\n",
      "Iteration 19, loss = 0.01108432\n",
      "Iteration 20, loss = 0.01511589\n",
      "Iteration 21, loss = 0.01175884\n",
      "Iteration 22, loss = 0.01106679\n",
      "Iteration 23, loss = 0.01372552\n",
      "Iteration 24, loss = 0.01256090\n",
      "Iteration 25, loss = 0.01146632\n",
      "Iteration 26, loss = 0.01278900\n",
      "Iteration 27, loss = 0.01257385\n",
      "Iteration 28, loss = 0.01101180\n",
      "Iteration 29, loss = 0.01362009\n",
      "Iteration 30, loss = 0.01361278\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.25942266\n",
      "Iteration 2, loss = 0.09434638\n",
      "Iteration 3, loss = 0.06228592\n",
      "Iteration 4, loss = 0.04675580\n",
      "Iteration 5, loss = 0.03554640\n",
      "Iteration 6, loss = 0.03347885\n",
      "Iteration 7, loss = 0.03217329\n",
      "Iteration 8, loss = 0.02504836\n",
      "Iteration 9, loss = 0.02549259\n",
      "Iteration 10, loss = 0.02259220\n",
      "Iteration 11, loss = 0.02163416\n",
      "Iteration 12, loss = 0.01825530\n",
      "Iteration 13, loss = 0.01716008\n",
      "Iteration 14, loss = 0.01589957\n",
      "Iteration 15, loss = 0.01569674\n",
      "Iteration 16, loss = 0.01731989\n",
      "Iteration 17, loss = 0.01635175\n",
      "Iteration 18, loss = 0.01880112\n",
      "Iteration 19, loss = 0.01857328\n",
      "Iteration 20, loss = 0.01477665\n",
      "Iteration 21, loss = 0.01086343\n",
      "Iteration 22, loss = 0.00938715\n",
      "Iteration 23, loss = 0.00839333\n",
      "Iteration 24, loss = 0.01033015\n",
      "Iteration 25, loss = 0.01051772\n",
      "Iteration 26, loss = 0.01326698\n",
      "Iteration 27, loss = 0.01212532\n",
      "Iteration 28, loss = 0.00803147\n",
      "Iteration 29, loss = 0.01387215\n",
      "Iteration 30, loss = 0.01155882\n",
      "Iteration 31, loss = 0.01095782\n",
      "Iteration 32, loss = 0.01188046\n",
      "Iteration 33, loss = 0.00905732\n",
      "Iteration 34, loss = 0.01037938\n",
      "Iteration 35, loss = 0.01126620\n",
      "Iteration 36, loss = 0.00581824\n",
      "Iteration 37, loss = 0.00793894\n",
      "Iteration 38, loss = 0.01093419\n",
      "Iteration 39, loss = 0.01312325\n",
      "Iteration 40, loss = 0.00902758\n",
      "Iteration 41, loss = 0.00645977\n",
      "Iteration 42, loss = 0.01190502\n",
      "Iteration 43, loss = 0.01061963\n",
      "Iteration 44, loss = 0.01115645\n",
      "Iteration 45, loss = 0.00727854\n",
      "Iteration 46, loss = 0.00890771\n",
      "Iteration 47, loss = 0.01042103\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.26595432\n",
      "Iteration 2, loss = 0.09769051\n",
      "Iteration 3, loss = 0.06192146\n",
      "Iteration 4, loss = 0.05048816\n",
      "Iteration 5, loss = 0.04000406\n",
      "Iteration 6, loss = 0.02885942\n",
      "Iteration 7, loss = 0.02782851\n",
      "Iteration 8, loss = 0.02530459\n",
      "Iteration 9, loss = 0.02552856\n",
      "Iteration 10, loss = 0.02299939\n",
      "Iteration 11, loss = 0.01951409\n",
      "Iteration 12, loss = 0.01854222\n",
      "Iteration 13, loss = 0.01673820\n",
      "Iteration 14, loss = 0.01549258\n",
      "Iteration 15, loss = 0.01768094\n",
      "Iteration 16, loss = 0.01525001\n",
      "Iteration 17, loss = 0.01431480\n",
      "Iteration 18, loss = 0.01790812\n",
      "Iteration 19, loss = 0.01459447\n",
      "Iteration 20, loss = 0.01461211\n",
      "Iteration 21, loss = 0.01477745\n",
      "Iteration 22, loss = 0.01425300\n",
      "Iteration 23, loss = 0.00850340\n",
      "Iteration 24, loss = 0.01269886\n",
      "Iteration 25, loss = 0.00938496\n",
      "Iteration 26, loss = 0.01090478\n",
      "Iteration 27, loss = 0.01028512\n",
      "Iteration 28, loss = 0.01602363\n",
      "Iteration 29, loss = 0.01356338\n",
      "Iteration 30, loss = 0.01130087\n",
      "Iteration 31, loss = 0.00769678\n",
      "Iteration 32, loss = 0.01014833\n",
      "Iteration 33, loss = 0.01603603\n",
      "Iteration 34, loss = 0.00908632\n",
      "Iteration 35, loss = 0.01036101\n",
      "Iteration 36, loss = 0.01208345\n",
      "Iteration 37, loss = 0.01134309\n",
      "Iteration 38, loss = 0.00706181\n",
      "Iteration 39, loss = 0.00588197\n",
      "Iteration 40, loss = 0.01098803\n",
      "Iteration 41, loss = 0.00923226\n",
      "Iteration 42, loss = 0.01096564\n",
      "Iteration 43, loss = 0.01221148\n",
      "Iteration 44, loss = 0.00966124\n",
      "Iteration 45, loss = 0.00940681\n",
      "Iteration 46, loss = 0.01084266\n",
      "Iteration 47, loss = 0.00936812\n",
      "Iteration 48, loss = 0.00882337\n",
      "Iteration 49, loss = 0.00749939\n",
      "Iteration 50, loss = 0.00816476\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.26029638\n",
      "Iteration 2, loss = 0.09847848\n",
      "Iteration 3, loss = 0.06498288\n",
      "Iteration 4, loss = 0.04630261\n",
      "Iteration 5, loss = 0.03714278\n",
      "Iteration 6, loss = 0.03322169\n",
      "Iteration 7, loss = 0.03037519\n",
      "Iteration 8, loss = 0.02776320\n",
      "Iteration 9, loss = 0.02337396\n",
      "Iteration 10, loss = 0.02370706\n",
      "Iteration 11, loss = 0.02224971\n",
      "Iteration 12, loss = 0.02007300\n",
      "Iteration 13, loss = 0.01667401\n",
      "Iteration 14, loss = 0.01648591\n",
      "Iteration 15, loss = 0.01633606\n",
      "Iteration 16, loss = 0.01597639\n",
      "Iteration 17, loss = 0.01210803\n",
      "Iteration 18, loss = 0.01507355\n",
      "Iteration 19, loss = 0.01270864\n",
      "Iteration 20, loss = 0.01319542\n",
      "Iteration 21, loss = 0.01010770\n",
      "Iteration 22, loss = 0.01378481\n",
      "Iteration 23, loss = 0.01486968\n",
      "Iteration 24, loss = 0.01097422\n",
      "Iteration 25, loss = 0.01291413\n",
      "Iteration 26, loss = 0.01429144\n",
      "Iteration 27, loss = 0.00941051\n",
      "Iteration 28, loss = 0.01020686\n",
      "Iteration 29, loss = 0.00591664\n",
      "Iteration 30, loss = 0.01167642\n",
      "Iteration 31, loss = 0.01538287\n",
      "Iteration 32, loss = 0.01245554\n",
      "Iteration 33, loss = 0.00826554\n",
      "Iteration 34, loss = 0.00582598\n",
      "Iteration 35, loss = 0.00742820\n",
      "Iteration 36, loss = 0.00822457\n",
      "Iteration 37, loss = 0.01537711\n",
      "Iteration 38, loss = 0.01351681\n",
      "Iteration 39, loss = 0.00850098\n",
      "Iteration 40, loss = 0.00859388\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.25869795\n",
      "Iteration 2, loss = 0.09882465\n",
      "Iteration 3, loss = 0.06105532\n",
      "Iteration 4, loss = 0.04698819\n",
      "Iteration 5, loss = 0.03742942\n",
      "Iteration 6, loss = 0.03345536\n",
      "Iteration 7, loss = 0.02957930\n",
      "Iteration 8, loss = 0.02234242\n",
      "Iteration 9, loss = 0.02443862\n",
      "Iteration 10, loss = 0.01954539\n",
      "Iteration 11, loss = 0.02227830\n",
      "Iteration 12, loss = 0.02118938\n",
      "Iteration 13, loss = 0.01493409\n",
      "Iteration 14, loss = 0.01929105\n",
      "Iteration 15, loss = 0.01520710\n",
      "Iteration 16, loss = 0.01833500\n",
      "Iteration 17, loss = 0.01676817\n",
      "Iteration 18, loss = 0.01690190\n",
      "Iteration 19, loss = 0.01278052\n",
      "Iteration 20, loss = 0.01054699\n",
      "Iteration 21, loss = 0.01475359\n",
      "Iteration 22, loss = 0.01417681\n",
      "Iteration 23, loss = 0.01433415\n",
      "Iteration 24, loss = 0.01093401\n",
      "Iteration 25, loss = 0.01003754\n",
      "Iteration 26, loss = 0.01303277\n",
      "Iteration 27, loss = 0.01258412\n",
      "Iteration 28, loss = 0.01362160\n",
      "Iteration 29, loss = 0.00976331\n",
      "Iteration 30, loss = 0.00887693\n",
      "Iteration 31, loss = 0.01125741\n",
      "Iteration 32, loss = 0.00883783\n",
      "Iteration 33, loss = 0.01080026\n",
      "Iteration 34, loss = 0.00649148\n",
      "Iteration 35, loss = 0.01017252\n",
      "Iteration 36, loss = 0.01127387\n",
      "Iteration 37, loss = 0.01237084\n",
      "Iteration 38, loss = 0.01134833\n",
      "Iteration 39, loss = 0.01164287\n",
      "Iteration 40, loss = 0.01159063\n",
      "Iteration 41, loss = 0.01057085\n",
      "Iteration 42, loss = 0.01094272\n",
      "Iteration 43, loss = 0.00915664\n",
      "Iteration 44, loss = 0.00543808\n",
      "Iteration 45, loss = 0.00395956\n",
      "Iteration 46, loss = 0.01057480\n",
      "Iteration 47, loss = 0.01530191\n",
      "Iteration 48, loss = 0.01056784\n",
      "Iteration 49, loss = 0.00621769\n",
      "Iteration 50, loss = 0.01268310\n",
      "Iteration 51, loss = 0.00871166\n",
      "Iteration 52, loss = 0.00824779\n",
      "Iteration 53, loss = 0.00671144\n",
      "Iteration 54, loss = 0.00622146\n",
      "Iteration 55, loss = 0.01243241\n",
      "Iteration 56, loss = 0.01029854\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.26358183\n",
      "Iteration 2, loss = 0.09702643\n",
      "Iteration 3, loss = 0.06590500\n",
      "Iteration 4, loss = 0.05117795\n",
      "Iteration 5, loss = 0.03796078\n",
      "Iteration 6, loss = 0.03471144\n",
      "Iteration 7, loss = 0.02542694\n",
      "Iteration 8, loss = 0.03032809\n",
      "Iteration 9, loss = 0.02448204\n",
      "Iteration 10, loss = 0.02081570\n",
      "Iteration 11, loss = 0.02034846\n",
      "Iteration 12, loss = 0.02025308\n",
      "Iteration 13, loss = 0.01861680\n",
      "Iteration 14, loss = 0.01647086\n",
      "Iteration 15, loss = 0.01534367\n",
      "Iteration 16, loss = 0.02250066\n",
      "Iteration 17, loss = 0.01466507\n",
      "Iteration 18, loss = 0.01445743\n",
      "Iteration 19, loss = 0.01122042\n",
      "Iteration 20, loss = 0.01294562\n",
      "Iteration 21, loss = 0.00986470\n",
      "Iteration 22, loss = 0.01580464\n",
      "Iteration 23, loss = 0.01263473\n",
      "Iteration 24, loss = 0.01334458\n",
      "Iteration 25, loss = 0.01032331\n",
      "Iteration 26, loss = 0.01257690\n",
      "Iteration 27, loss = 0.00865085\n",
      "Iteration 28, loss = 0.00731462\n",
      "Iteration 29, loss = 0.01189589\n",
      "Iteration 30, loss = 0.01433264\n",
      "Iteration 31, loss = 0.01234452\n",
      "Iteration 32, loss = 0.01337726\n",
      "Iteration 33, loss = 0.00782519\n",
      "Iteration 34, loss = 0.00914208\n",
      "Iteration 35, loss = 0.01014170\n",
      "Iteration 36, loss = 0.01057880\n",
      "Iteration 37, loss = 0.01276541\n",
      "Iteration 38, loss = 0.00966862\n",
      "Iteration 39, loss = 0.01030676\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "scores_mlp = []\n",
    "for i in range(1):\n",
    "    kfold = KFold(n_splits=10,shuffle=True,random_state=i)\n",
    "    arvore = MLPClassifier(max_iter=1500,verbose=True,hidden_layer_sizes=(397,397,397,397),activation='relu')\n",
    "    cross_score = cross_val_score(arvore,x_mnist,y_mnist,cv=kfold)\n",
    "    scores_mlp.append(cross_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.9766)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_mlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
